<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">

<html>

<head>
	<title>Learning to Detect Humans-Objects Interactions</title>
</head>

<body>
	<!-- Start of Page Table Layout -->
	<table border=0 width=1000px align=center>
		<tr>
			<td>

				<!-- Page Title -->
				<center>
					<h1>
						<font face=helvetica style="font-size:90%">Learning to Detect Humans-Objects Interactions</font>
					</h1>
				</center>
				<br>

				<center>
					<font face=helvetica style=font-size:18px>
						<b>Supervisor:</b> Jia Deng | <b>Co-author:</b> Yu-Wei Chao, Xieyang Liu
					</font>
				</center><br><br>

				<center>
					<img src="HOI/HOI_Examples_horizontal.png" height="150">
				</center><br>

				<!-- Goal -->
				<h2><font face=helvetica style=font-size:24px>Goal</font></h2>
				<hr style="margin-top:-10px; margin-bottom:-5px">
				<p align=justify>
					<font face=helvetica style=font-size:18px>
						The goal of the project was to detect and label human-object interactions (HOI) in static images, instead of only focusing on either single object detection or action recognition. As show in the above figure, people are encircled by blue boxes and objects by green boxes. Each red line links indicate the interaction of desired category between people and objects.
					</font>
				</p><br>

				<!-- Method -->
				<h2><font face=helvetica style=font-size:24px>Method</font></h2>
				<hr style="margin-top:-10px; margin-bottom:-5px">
				<p align=justify>
					<font face=helvetica style=font-size:18px>
						The goal is approached in two phases: human/object bounding boxes detection and HOI classification. In the first phase, we trained Fast-rcnn detectors with images containing 80 object categories (including human) and achieved the goal of human/object bounding box detection. For the second phase, we proposed a multi-streamed deep neural network to extract features from human pose as well as local object texture, and learn spatial relation from interaction pattern.
					</font>
				</p>	

				<br>
				<center>
					<img src="HOI/HOI_Three_Stream.png" width = "700" alt="" />
				</center>
				<br>

				<p align=justify>
					<font face=helvetica style=font-size:18px>
						The most difficult challenge of the project lies in the extensive variation of relationship of human and objects in natural scenes. To tackle the variation, We investigated on the distribution of ground truth bounding boxes of human and objects and concluded that spatial relations of human and objects could be clustered in several main patterns. We then developed an input channel that included description of interaction patterns with the lowest granularity by ignoring the pixel intensities. Incorporating this interaction pattern channel to human and object streams boosted the HOI detection performance by more than 26.50% of mAP on HICO-DET.
					</font>
				</p><br>		

				<!-- Results -->
				<h2><font face=helvetica style=font-size:24px>Results</font></h2>
				<hr style="margin-top:-10px; margin-bottom:-5px">
				<p align=justify>
					<font face=helvetica style=font-size:18px>
						Some of the sample results are shown as follows (numbers are the confident scores generated by the network). This work has been submitted to CVPR 2017, and the source code as well as more detailed experiment result will be released upon acceptance. Stay Tuned!
					</font>
				</p>

				<br>
				<center>
					<img src="HOI/HOI_Results.png" width = "700" alt="" />
				</center>
				<br>

				<hr>
				<font face=helvetica style=font-size:15px>Last updated on 2016/12/25</font>
			</td>
		</tr>

</body>
</html>
