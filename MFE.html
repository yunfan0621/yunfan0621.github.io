<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">

<html>

<head>
	<title>Learning to Detect Humans-Objects Interactions</title>
</head>

<body>
	<!-- Start of Page Table Layout -->
	<table border=0 width=1000px align=center>
		<tr>
			<td>

				<!-- Page Title -->
				<center>
					<h1>
						<font face=helvetica style="font-size:90%">Vision-based Micro-Expression Analysis</font>
					</h1>
				</center>
				<br>

				<center>
					<font face=helvetica style=font-size:18px>
						<b>Institute of Information Cognition and Intelligent System, Tsinghua University</b><br />
						<br>
						<b>Supervisor:</b> <a href="http://jschenthu.weebly.com/" target="_blank">Jiansheng Chen</a>
					</font>
				</center><br><br>

				<!-- Goal -->
				<h2><font face=helvetica style=font-size:24px>Goal</font></h2>
				<hr style="margin-top:-10px; margin-bottom:-5px">
				<p align=justify>
					<font face=helvetica style=font-size:18px>
						The goal of the project was to investigate on the problem of micro-expression analysis from visual perspctive. As oppose to normal-expression, micro-expression is a kind of subconscious expression that could reveal actual and suppressed emotion, so it possesses high research value in criminal investigation and medical consultation. The short duration and subtle facial movement makes it hard for human beings to recognize micro-expression. Therefore, high frame rate data acquisition and computer vision techniques are employed in the analysis.
					</font>
				</p><br>

				<!-- Data Acquisition -->
				<h2><font face=helvetica style=font-size:24px>Data Acquisition</font></h2>
				<hr style="margin-top:-10px; margin-bottom:-5px">
				<p align=justify>
					<font face=helvetica style=font-size:18px>
						The main problem in existing databases is the fixed head posture, which makes the algorithm impractical for natural scene processing. To tackle with this problem, we improved the experiment settings by including macro head motion (both in-plane and out-plane movement) and recording the videos using high frame rate video camera. We designed and conducted experiments using ideas borrowed from psychological literature to collect raw video data with high frame rate to capture subtle facial movement and established a dataset with annotations. Sample frames are shown below.
					</font>
				</p>

				<br>
				<center>
					<img src="MFE/Sample_frames.png" width = "700" alt="" />
				</center>
				<br>

				<p align=justify>
					<font face=helvetica style=font-size:18px>
						The video recorder we used in our experiment is SONY NEX-FS700CK digial motion picture camera. The raw data is collected under 480fps, 720p configuration, which is sufficient for us to capture the micro-expression. 40 videos are recorded in total and the average length is 2.5~3.2s. A typical scene of data acquisition is shown as follows (this is not a very strict way to acquire data due to the limited resources we had in the project).
					</font>
				</p><br>

				<br>
				<center>
					<img src="MFE/Experiment_Setting.png" width = "700" alt="" />
				</center>
				<br>

				<!-- Method -->
				<h2><font face=helvetica style=font-size:24px>Method</font></h2>
				<hr style="margin-top:-10px; margin-bottom:-5px">
				<p align=justify>
					<font face=helvetica style=font-size:18px>
						Close observation reveals that the overall movement (head movement and facial expression) can be decomposed in three separate parts: <b>in-plane motion</b>, <b>out-plane motion</b> and <b>micro-expression</b>. Following this idea, we could get rid of head movement and extract the micro-expression.
							 <ol>
							  <!-- Step 1 -->
							  <li>
							  	<p align=justify>
							  		The characteristic of in-plane movement is that the general structure of human face remains the same during the process, despite the subtle distortion caused by micro-expression and occlusion due to out-plane motion. Thus if we vectorize each frame and group them in a matrix, the matrix should be of <b>low rank</b>. Then we could model the in-plane movement as image transformation and remove it via <b>Robust PCA</b>.
							  	</p>

							  	<br>
							  	<center>
							  		<img src="MFE/modelling.png" width = "700" alt="" />
							  	</center>
							  	<br>

							  	<p align=justify>
							  		As shown in the above figure, <i>d</i> is the instance of the movement we observe in the images; &tau; is the in-plane movement that we consider as image transformation; <i>a</i> is the general facial structure; <i>e</i> is the subtle noise caused by out-plane movement and micro-expression. This could be considered as a <b>Robust PCA</b> problem, and the in-plane movement &tau; could be solved and removed from the video. The result is shown as follow.
							  	</p>

							  	<br>
							  	<center>
							  		<img src="MFE/After_Robust_PCA.png" width = "700" alt="" />
							  	</center>
							  	<br>

							  <!-- Step 2 -->
  							  <li>
							  	<p align=justify>
							  		We could not simply apply the same technique to the out-plane movement due to the occlusion caused by it. However, observation shows that the <b>motion trails</b> of pixels still have the low rank property, and this time we could treat the micro-expression as the sparse error. In this way, we could separate out-plane movement and micro-expression. Optical flow method is employed to track the motion of pixels along the image sequence.
							  	</p>

							  </li>

							</ol> 
					</font>
				</p>		

				<!-- Result -->
				<h2><font face=helvetica style=font-size:24px>Sample Result</font></h2>
				<hr style="margin-top:-10px; margin-bottom:-5px">
				<p align=justify>
					<font face=helvetica style=font-size:18px>
						A micro-expression detection result is shown as follows. As can be seen from the sampled image sequence (upper figure), the expression is very hard to observe, not to mention the head movement will introduce great noise thus degrade SNR (the general head movement maybe not obvious since the images are sampled in a short time period). The lower figure shows the micro-expression detection result. THe result successfully recognizes the motion near the mouth corners, but it also take the movement of eyes and illumination change near the noise as micro-expression by mistake. This result demonstrates the main difficulty embedded in micro-expression analysis - the small amplitude of expression. On the other hand, it also illustrates the ability of our algorithm to detection subtle motion (as oppose to expression-related motion) in nature complicated scenes.
					</font>	
				</p>

				<br>
				<center>
					<img src="MFE/Sample_Micro_Expression.png" width = "700" alt="" /><br />
					<img src="MFE/Micro_Expression_Result.png" width = "150" alt="" />
				</center>
				<br>


				<!-- Further Application -->
				<h2><font face=helvetica style=font-size:24px>Further Application and Problems</font></h2>
				<hr style="margin-top:-10px; margin-bottom:-5px">
				<p align=justify>
					<font face=helvetica style=font-size:18px>
						Since we could extract the motion of micro-expression, magnification and classification are two handy further applications. Besides, this project demonstrates that the Robust PCA is a very efficient algorithm in vdeo processing as the low property is universally embedded in image sequences (I believe this is more inspiring than micro-expression analysis itself). <br /><br>

						Experiment result shows that the low amplitude of expression is the key issue of the micro-expression analysis. The intensity change cause by the micro-expression is comparable with that caused by illumination change or even noise, thus we have an exremely poor SNR in this system. In order to improve performance of the algorithm, a beeter detection algorithm should be proposed in the future.
					</font>
				</p>



				<ul class="actions">
					<li><a href="index.html" class="button">Return To Home</a></li>
				</ul>

				<hr>
				<font face=helvetica style=font-size:15px>Last updated on 2016/12/27</font>
			</td>
		</tr>

</body>
</html>
